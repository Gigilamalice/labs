# From ACM, deploy an application to each cluster

In this section, you will deploy a simple apache server to each cluster. The web server will use a `ConfigMap` to print out which cluster you are on. In the next lab, the application will be load balanced behind an HAProxy instance to finalize the end to end deployment.

## Prereqs
* OpenShift Clusters Running on Different Providers Managed by ACM
* Github repo Cloned Locally

### Set up your OpenShift Contexts

OC Tool Context Configuration

The following steps will leverage the usage of contexts within the oc tool.

We will be using four contexts:

* `hub` -> Context for accesing HUB Cluster
* `aws-spoke` -> Context for accesing AWS SPOKE Cluster
* `gcp-spoke` -> Context for accesing GCP SPOKE Cluster
* `azure-spoke` -> Context for accesing Azure SPOKE Cluster

Download all of your kubeconfig files for each spoke from ACM. If you don't know how to merge your Kubeconfigs and create the context you can refer to [this documentation[(https://openshift.tips/oc/#merge-multiple-kubeconfigs)

## Provision the Application

1. Explore the spoke clusters. You will notice that there are no application projects in any of the environments.

``` 
oc config use aws-admin
oc config current-context
oc get projects

oc config use gcp-admin
oc config current-context
oc get projects

oc config use azure-admin
oc config current-context
oc get projects
``` 

**NOTE:** To review the application repo, clone it and explore.

```
git clone https://gitlab.cee.redhat.com/scollier/acm-infrastructure.git 
```

2. Deploy the application.

```
cd assets/app/acm
oc --context hub apply -f .
```

3. Explore the spoke clusters and create the route. You will notice that there are now application projects in all of the environments.

``` 
oc --context aws-admin get projects | grep apache
oc --context aws-admin project aws-apache-test
oc --context aws-admin expose service apache-service
oc --context aws-admin get all

oc --context gcp-admin get projects | grep apache
oc --context gcp-admin project gcp-apache-test
oc --context gcp-admin expose service apache-service
oc --context gcp-admin get all

oc --context azure-admin get projects | grep apache
oc --context azure-admin project azure-apache-test
oc --context azure-admin expose service apache-service
oc --context azure-admin get all
``` 


4. Confirm Application Access by making a note of the routes for each cluster above and accessing them directly. Also, they will be used for the configuration of HAProxy. Make sure to replace the DNS name below with your routes.

```
curl http://apache-service-aws-apache-test.apps.aws-spoke-1.<engineer>.sysdeseng.com
curl http://apache-service-gcp-apache-test.apps.gcp-spoke-1.<engineer>.sysdeseng.com
curl http://apache-service-azure-apache-test.apps.azure-spoke-1.<engineer>.sysdeseng.com
```

5. Patch the OpenShift route on each cluster to reflect the DNS name of the HAProxy instance so that OpenShift can interpret the header corretly.

**NOTE:** This should be done in the git repository. However, for now, for the sake of time, we are patching the routes directly.

```
oc patch route apache-service -n gcp-apache-test -p '{"spec":{"host": "haproxy.<engineer>.sysdeseng.com"}}'
oc patch route apache-service -n aws-apache-test -p '{"spec":{"host": "haproxy.<engineer>.sysdeseng.com"}}'
oc patch route apache-service -n azure-apache-test -p '{"spec":{"host": "haproxy.<engineer>.sysdeseng.com"}}'
```

---

**Continue to [Configure Load Balancer](./7.md)**

**Back to [Provision OCP on GCP - Creating a Spoke](./5.md)**

**Go [Home](../README.md)**
